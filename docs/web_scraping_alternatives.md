# üåê –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –ø–ª–∞—Ç–Ω—ã–º —Å–µ—Ä–≤–∏—Å–∞–º –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞

## üìã –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

–í —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **Serper API** –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞. –≠—Ç–æ –ø–ª–∞—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:
- –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

## üîÑ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã

### 1. **DuckDuckGo API** (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```python
import requests

def search_duckduckgo(query: str, max_results: int = 5) -> str:
    """
    –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo API.
    """
    url = "https://api.duckduckgo.com/"
    params = {
        'q': query,
        'format': 'json',
        'no_html': '1',
        'skip_disambig': '1'
    }
    
    response = requests.get(url, params=params)
    data = response.json()
    
    results = []
    for result in data.get('Results', [])[:max_results]:
        results.append(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {result.get('Title', '')}")
        results.append(f"–°—Å—ã–ª–∫–∞: {result.get('FirstURL', '')}")
        results.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {result.get('Text', '')}")
        results.append("-----------------")
    
    return '\n'.join(results)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞
- ‚úÖ –•–æ—Ä–æ—à–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å
- ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- ‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- ‚ùå –ú–µ–Ω—å—à–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å Google

### 2. **Selenium + BeautifulSoup** (–î–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞)

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time

def scrape_with_selenium(url: str) -> str:
    """
    –°–∫—Ä–∞–ø–∏–Ω–≥ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü —Å –ø–æ–º–æ—â—å—é Selenium.
    """
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # –ë–µ–∑ GUI
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    driver = webdriver.Chrome(options=chrome_options)
    
    try:
        driver.get(url)
        time.sleep(2)  # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
        
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text_content = soup.get_text()
        
        return text_content[:2000]  # –ü–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤
        
    finally:
        driver.quit()
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –ø—Ä–æ—Ü–µ—Å—Å–æ–º
- ‚úÖ –ú–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å JavaScript
- ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- ‚ùå –¢—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Chrome/ChromeDriver
- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ API
- ‚ùå –ú–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω —Å–∞–π—Ç–∞–º–∏

### 3. **Requests + BeautifulSoup** (–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∞–ø–∏–Ω–≥)

```python
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

def simple_scrape(url: str) -> str:
    """
    –ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∞–ø–∏–Ω–≥ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    response = requests.get(url, headers=headers, timeout=10)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
    for script in soup(["script", "style"]):
        script.decompose()
    
    text = soup.get_text()
    lines = (line.strip() for line in text.splitlines())
    chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
    text = ' '.join(chunk for chunk in chunks if chunk)
    
    return text[:2000]
```

### 4. **Scrapy** (–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥)

```python
import scrapy
from scrapy.crawler import CrawlerProcess

class WebSpider(scrapy.Spider):
    name = 'web_spider'
    
    def __init__(self, start_urls=None, *args, **kwargs):
        super(WebSpider, self).__init__(*args, **kwargs)
        self.start_urls = start_urls or []
    
    def parse(self, response):
        yield {
            'url': response.url,
            'title': response.css('title::text').get(),
            'content': response.css('body::text').get()
        }

def scrape_with_scrapy(urls: list) -> list:
    """
    –°–∫—Ä–∞–ø–∏–Ω–≥ —Å –ø–æ–º–æ—â—å—é Scrapy.
    """
    process = CrawlerProcess({
        'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    })
    
    process.crawl(WebSpider, start_urls=urls)
    process.start()
    
    return process.crawler.stats.get_stats()
```

## üõ†Ô∏è –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–æ–µ–∫—Ç

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ web_tools.py

```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ web_tools.py
class FreeWebSearchTools:
    """–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤–µ–±-–ø–æ–∏—Å–∫–∞."""
    
    @tool("–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ø–æ–∏—Å–∫")
    def free_search(self, query: str) -> str:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo."""
        return search_duckduckgo(query)
    
    @tool("–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∞–ø–∏–Ω–≥")
    def simple_scrape(self, url: str) -> str:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü."""
        return simple_scrape(url)
```

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤

```python
# –í crew —Ñ–∞–π–ª–∞—Ö –¥–æ–±–∞–≤–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
from marketing_posts.core.web_tools import FreeWebSearchTools

free_tools = FreeWebSearchTools()

# –î–æ–±–∞–≤–∏—Ç—å –∫ –∞–≥–µ–Ω—Ç–∞–º
tools=[
    free_tools.free_search,
    free_tools.simple_scrape
]
```

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤

| –ú–µ—Ç–æ–¥ | –°—Ç–æ–∏–º–æ—Å—Ç—å | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|-------|-----------|----------|----------|-----------|
| Serper API | üí∞ –ü–ª–∞—Ç–Ω—ã–π | ‚ö° –ë—ã—Å—Ç—Ä—ã–π | üü¢ –í—ã—Å–æ–∫–æ–µ | üü¢ –ü—Ä–æ—Å—Ç–∞—è |
| DuckDuckGo | üÜì –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π | üü° –°—Ä–µ–¥–Ω—è—è | üü° –°—Ä–µ–¥–Ω–µ–µ | üü¢ –ü—Ä–æ—Å—Ç–∞—è |
| Selenium | üÜì –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π | üî¥ –ú–µ–¥–ª–µ–Ω–Ω—ã–π | üü¢ –í—ã—Å–æ–∫–æ–µ | üî¥ –°–ª–æ–∂–Ω–∞—è |
| Requests+BS | üÜì –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π | üü° –°—Ä–µ–¥–Ω—è—è | üü° –°—Ä–µ–¥–Ω–µ–µ | üü° –°—Ä–µ–¥–Ω—è—è |
| Scrapy | üÜì –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π | ‚ö° –ë—ã—Å—Ç—Ä—ã–π | üü¢ –í—ã—Å–æ–∫–æ–µ | üî¥ –°–ª–æ–∂–Ω–∞—è |

## üöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
1. **DuckDuckGo API** - –ª—É—á—à–∏–π –≤—ã–±–æ—Ä
2. **Requests + BeautifulSoup** - –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:
1. **Serper API** - –µ—Å–ª–∏ –±—é–¥–∂–µ—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç
2. **DuckDuckGo + Selenium** - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥

### –î–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:
1. **Scrapy** - –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
2. **–ü—Ä–æ–∫—Å–∏-—Ä–æ—Ç–∞—Ü–∏—è** - –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –î–ª—è Selenium
pip install selenium webdriver-manager

# –î–ª—è BeautifulSoup
pip install beautifulsoup4 lxml

# –î–ª—è Scrapy
pip install scrapy
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ChromeDriver

```python
from webdriver_manager.chrome import ChromeDriverManager
from selenium import webdriver

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞
driver = webdriver.Chrome(ChromeDriverManager().install())
```

### 3. –†–æ—Ç–∞—Ü–∏—è User-Agent

```python
import random

user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'
]

headers = {'User-Agent': random.choice(user_agents)}
```

## ‚ö†Ô∏è –ü—Ä–∞–≤–æ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã

### –í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:
1. **Respect robots.txt** - –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ
2. **Rate limiting** - –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞–π—Ç–µ —Å–µ—Ä–≤–µ—Ä—ã
3. **Terms of Service** - —Å–æ–±–ª—é–¥–∞–π—Ç–µ —É—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
4. **GDPR/CCPA** - —É—á–∏—Ç—ã–≤–∞–π—Ç–µ –∑–∞–∫–æ–Ω—ã –æ –¥–∞–Ω–Ω—ã—Ö

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
- –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
- –õ–æ–≥–∏—Ä—É–π—Ç–µ –≤—Å–µ –¥–µ–π—Å—Ç–≤–∏—è
- –ü–æ–ª—É—á–∞–π—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

### –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤

### –ê–ª–µ—Ä—Ç—ã:
- –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤
- –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫
- –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ IP

## üîÆ –ë—É–¥—É—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è

### –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
1. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**
2. **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**
3. **–£–º–Ω–∞—è —Ä–æ—Ç–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏**
4. **–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞**
5. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö**

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
1. **–ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**
2. **–û—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á**
3. **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ**
4. **API Gateway**
5. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏** 